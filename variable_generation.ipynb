{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file 'video1.txt' as: https://generativelanguage.googleapis.com/v1beta/files/vgottmimvvcg\n",
      "Uploaded file 'video2.txt' as: https://generativelanguage.googleapis.com/v1beta/files/q01lsq53k0jf\n",
      "Uploaded file 'video3.txt' as: https://generativelanguage.googleapis.com/v1beta/files/lxdg9mxxxyop\n",
      "Uploaded file 'video4.txt' as: https://generativelanguage.googleapis.com/v1beta/files/6bh1wcfica3h\n",
      "Uploaded file 'video5.txt' as: https://generativelanguage.googleapis.com/v1beta/files/m8s91ly7215r\n",
      "Uploaded file 'video6.txt' as: https://generativelanguage.googleapis.com/v1beta/files/bvsc6hd40loi\n",
      "Uploaded file 'video7.txt' as: https://generativelanguage.googleapis.com/v1beta/files/t8vizrf83hk0\n",
      "Uploaded file 'video8.txt' as: https://generativelanguage.googleapis.com/v1beta/files/wuhuudzotwjp\n",
      "Uploaded file 'video9.txt' as: https://generativelanguage.googleapis.com/v1beta/files/btplp8m9svnk\n",
      "Uploaded file 'video10.txt' as: https://generativelanguage.googleapis.com/v1beta/files/ncv6fjic38ce\n",
      "Uploaded file 'video11.txt' as: https://generativelanguage.googleapis.com/v1beta/files/aymgbj4i7s1p\n",
      "Uploaded file 'video12.txt' as: https://generativelanguage.googleapis.com/v1beta/files/348dzvxtc2tj\n",
      "Uploaded file 'video13.txt' as: https://generativelanguage.googleapis.com/v1beta/files/6nnaut132dbk\n",
      "Uploaded file 'video14.txt' as: https://generativelanguage.googleapis.com/v1beta/files/ucmqxc3e8n43\n",
      "Uploaded file 'video15.txt' as: https://generativelanguage.googleapis.com/v1beta/files/s1lapjhxnem6\n",
      "Uploaded file 'video16.txt' as: https://generativelanguage.googleapis.com/v1beta/files/76dg5sin59oa\n",
      "Uploaded file 'video17.txt' as: https://generativelanguage.googleapis.com/v1beta/files/gfnhoqmc41bn\n",
      "Uploaded file 'video18.txt' as: https://generativelanguage.googleapis.com/v1beta/files/b78vg8sa7k1e\n",
      "Uploaded file 'video19.txt' as: https://generativelanguage.googleapis.com/v1beta/files/7f7nv77mhgy9\n",
      "Uploaded file 'video20.txt' as: https://generativelanguage.googleapis.com/v1beta/files/rvg9mo26xxbe\n",
      "Uploaded file 'video21.txt' as: https://generativelanguage.googleapis.com/v1beta/files/ud85k0w1svlt\n",
      "Uploaded file 'video22.txt' as: https://generativelanguage.googleapis.com/v1beta/files/kcbamti2yils\n",
      "Uploaded file 'video23.txt' as: https://generativelanguage.googleapis.com/v1beta/files/ehacu2qok9x7\n",
      "Uploaded file 'video24.txt' as: https://generativelanguage.googleapis.com/v1beta/files/xfjmqzfsrog2\n",
      "Uploaded file 'video25.txt' as: https://generativelanguage.googleapis.com/v1beta/files/taujhfsh6bbh\n",
      "Uploaded file 'video26.txt' as: https://generativelanguage.googleapis.com/v1beta/files/33sqaifev10a\n",
      "Uploaded file 'video27.txt' as: https://generativelanguage.googleapis.com/v1beta/files/tejt32i4bte0\n",
      "Uploaded file 'video28.txt' as: https://generativelanguage.googleapis.com/v1beta/files/9p0o7510cob3\n",
      "Uploaded file 'video29.txt' as: https://generativelanguage.googleapis.com/v1beta/files/mjkb0sg78xoo\n",
      "Uploaded file 'video30.txt' as: https://generativelanguage.googleapis.com/v1beta/files/8a7cp9mnwyo9\n",
      "Uploaded file 'video31.txt' as: https://generativelanguage.googleapis.com/v1beta/files/joblqml6pcse\n",
      "Uploaded file 'video32.txt' as: https://generativelanguage.googleapis.com/v1beta/files/t35xtg4wra82\n",
      "Uploaded file 'video33.txt' as: https://generativelanguage.googleapis.com/v1beta/files/sh5q2rkjynm5\n",
      "Uploaded file 'video34.txt' as: https://generativelanguage.googleapis.com/v1beta/files/zvv810ysqq7b\n",
      "Uploaded file 'video35.txt' as: https://generativelanguage.googleapis.com/v1beta/files/ladmascjevs2\n",
      "Uploaded file 'video36.txt' as: https://generativelanguage.googleapis.com/v1beta/files/72vl5ulcnwj7\n",
      "video37.txt is not found\n",
      "Uploaded file 'video38.txt' as: https://generativelanguage.googleapis.com/v1beta/files/6ddizi25grdj\n",
      "Uploaded file 'video39.txt' as: https://generativelanguage.googleapis.com/v1beta/files/3jv2la2wwdtr\n",
      "Uploaded file 'video40.txt' as: https://generativelanguage.googleapis.com/v1beta/files/fbbpxud61eib\n",
      "Uploaded file 'video41.txt' as: https://generativelanguage.googleapis.com/v1beta/files/zc1ph11qrmkg\n",
      "Uploaded file 'video42.txt' as: https://generativelanguage.googleapis.com/v1beta/files/nl50m8jb9rps\n",
      "Uploaded file 'video43.txt' as: https://generativelanguage.googleapis.com/v1beta/files/dcdkyxml3dqb\n",
      "Uploaded file 'video44.txt' as: https://generativelanguage.googleapis.com/v1beta/files/5fjy3qbzml8z\n",
      "Uploaded file 'video45.txt' as: https://generativelanguage.googleapis.com/v1beta/files/epzykg5ginqt\n",
      "Uploaded file 'video46.txt' as: https://generativelanguage.googleapis.com/v1beta/files/xwxmkmgsaqfk\n",
      "Uploaded file 'video47.txt' as: https://generativelanguage.googleapis.com/v1beta/files/gxj868v3vfnv\n",
      "Uploaded file 'video48.txt' as: https://generativelanguage.googleapis.com/v1beta/files/366wzc6bj7de\n",
      "Uploaded file 'video49.txt' as: https://generativelanguage.googleapis.com/v1beta/files/uh9jyxqwwuoo\n",
      "Uploaded file 'video50.txt' as: https://generativelanguage.googleapis.com/v1beta/files/m3mwasmwwgs8\n",
      "Uploaded file 'video51.txt' as: https://generativelanguage.googleapis.com/v1beta/files/om9kqo237o6e\n",
      "Uploaded file 'video52.txt' as: https://generativelanguage.googleapis.com/v1beta/files/sw152tdd3q6x\n",
      "Uploaded file 'video53.txt' as: https://generativelanguage.googleapis.com/v1beta/files/av10rx0sd81z\n",
      "Uploaded file 'video54.txt' as: https://generativelanguage.googleapis.com/v1beta/files/5oo2v5td6480\n",
      "Uploaded file 'video55.txt' as: https://generativelanguage.googleapis.com/v1beta/files/lpbo62ws021y\n",
      "Uploaded file 'video56.txt' as: https://generativelanguage.googleapis.com/v1beta/files/b12nyqgtso16\n",
      "Uploaded file 'video57.txt' as: https://generativelanguage.googleapis.com/v1beta/files/82nj5fd7cqvj\n",
      "Uploaded file 'video58.txt' as: https://generativelanguage.googleapis.com/v1beta/files/o046z8gy8pmf\n",
      "Uploaded file 'video59.txt' as: https://generativelanguage.googleapis.com/v1beta/files/liuhraxf3ef1\n",
      "Uploaded file 'video60.txt' as: https://generativelanguage.googleapis.com/v1beta/files/bdxoooxmbqrm\n",
      "Uploaded file 'video61.txt' as: https://generativelanguage.googleapis.com/v1beta/files/yf9fonex6dbq\n",
      "Uploaded file 'video62.txt' as: https://generativelanguage.googleapis.com/v1beta/files/l2selcl4sp4h\n",
      "Uploaded file 'video63.txt' as: https://generativelanguage.googleapis.com/v1beta/files/wfpnsmixr7z\n",
      "Uploaded file 'video64.txt' as: https://generativelanguage.googleapis.com/v1beta/files/nz0ugliommfu\n",
      "Uploaded file 'video65.txt' as: https://generativelanguage.googleapis.com/v1beta/files/auluzsjmnudp\n",
      "Uploaded file 'video66.txt' as: https://generativelanguage.googleapis.com/v1beta/files/zvfis3s77eym\n",
      "Uploaded file 'video67.txt' as: https://generativelanguage.googleapis.com/v1beta/files/nepuzzbquh8k\n",
      "Uploaded file 'video68.txt' as: https://generativelanguage.googleapis.com/v1beta/files/seo07320k8cp\n",
      "Uploaded file 'video69.txt' as: https://generativelanguage.googleapis.com/v1beta/files/kh4ijqjigzys\n",
      "Uploaded file 'video70.txt' as: https://generativelanguage.googleapis.com/v1beta/files/qhnbnfl1rdyv\n",
      "Uploaded file 'video71.txt' as: https://generativelanguage.googleapis.com/v1beta/files/jkxw5dxq9xwf\n",
      "Uploaded file 'video72.txt' as: https://generativelanguage.googleapis.com/v1beta/files/kmokibvwza87\n",
      "Uploaded file 'video73.txt' as: https://generativelanguage.googleapis.com/v1beta/files/k860e6wolewf\n",
      "Uploaded file 'video74.txt' as: https://generativelanguage.googleapis.com/v1beta/files/jxg00albwpt6\n",
      "Uploaded file 'video75.txt' as: https://generativelanguage.googleapis.com/v1beta/files/uavu031iiqyc\n",
      "Uploaded file 'video76.txt' as: https://generativelanguage.googleapis.com/v1beta/files/kqae6w4wn5tg\n",
      "Uploaded file 'video77.txt' as: https://generativelanguage.googleapis.com/v1beta/files/sbk0ci1j2ylv\n",
      "Uploaded file 'video78.txt' as: https://generativelanguage.googleapis.com/v1beta/files/vihgko3zgn4s\n",
      "Uploaded file 'video79.txt' as: https://generativelanguage.googleapis.com/v1beta/files/3cwhfja44u72\n",
      "Uploaded file 'video80.txt' as: https://generativelanguage.googleapis.com/v1beta/files/tmb7bg2e9e56\n",
      "Uploaded file 'video81.txt' as: https://generativelanguage.googleapis.com/v1beta/files/c581sfcnpkb4\n",
      "Uploaded file 'video82.txt' as: https://generativelanguage.googleapis.com/v1beta/files/tn72o1dhio3y\n",
      "Uploaded file 'video83.txt' as: https://generativelanguage.googleapis.com/v1beta/files/8wlo9ivfim3x\n",
      "Uploaded file 'video84.txt' as: https://generativelanguage.googleapis.com/v1beta/files/62f6iao2gg69\n",
      "Uploaded file 'video85.txt' as: https://generativelanguage.googleapis.com/v1beta/files/cbcmn9c1zaiy\n",
      "Uploaded file 'video86.txt' as: https://generativelanguage.googleapis.com/v1beta/files/30z5d45ki4gj\n",
      "Uploaded file 'video87.txt' as: https://generativelanguage.googleapis.com/v1beta/files/3y0fgifakzkj\n",
      "Uploaded file 'video88.txt' as: https://generativelanguage.googleapis.com/v1beta/files/e4nth868k4ko\n",
      "Uploaded file 'video89.txt' as: https://generativelanguage.googleapis.com/v1beta/files/sx2ltu7z5zaf\n",
      "Uploaded file 'video90.txt' as: https://generativelanguage.googleapis.com/v1beta/files/xswr0ipzum4h\n",
      "Uploaded file 'video91.txt' as: https://generativelanguage.googleapis.com/v1beta/files/lvj7g5s8sxtq\n",
      "Uploaded file 'video92.txt' as: https://generativelanguage.googleapis.com/v1beta/files/i6zs8xe988x3\n",
      "Uploaded file 'video93.txt' as: https://generativelanguage.googleapis.com/v1beta/files/43rvqh2wbr4j\n",
      "Uploaded file 'video94.txt' as: https://generativelanguage.googleapis.com/v1beta/files/jcwx418t225t\n",
      "Uploaded file 'video95.txt' as: https://generativelanguage.googleapis.com/v1beta/files/2klhtcw6gxwu\n",
      "Uploaded file 'video96.txt' as: https://generativelanguage.googleapis.com/v1beta/files/ybgo5j1dn3d5\n",
      "Uploaded file 'video97.txt' as: https://generativelanguage.googleapis.com/v1beta/files/fzxpc7whabi1\n",
      "Uploaded file 'video98.txt' as: https://generativelanguage.googleapis.com/v1beta/files/8nd1ddd71wt2\n",
      "Uploaded file 'video99.txt' as: https://generativelanguage.googleapis.com/v1beta/files/31b4y46trvwq\n",
      "Uploaded file 'video100.txt' as: https://generativelanguage.googleapis.com/v1beta/files/872k2dlfmit\n",
      "Uploaded file 'video101.txt' as: https://generativelanguage.googleapis.com/v1beta/files/3zs25gpw97i8\n",
      "Uploaded file 'video102.txt' as: https://generativelanguage.googleapis.com/v1beta/files/ounxf0igixaf\n",
      "Uploaded file 'video103.txt' as: https://generativelanguage.googleapis.com/v1beta/files/yrm8hl3lybxh\n",
      "Uploaded file 'video104.txt' as: https://generativelanguage.googleapis.com/v1beta/files/1qqnj0pv7nxh\n",
      "Uploaded file 'video105.txt' as: https://generativelanguage.googleapis.com/v1beta/files/9r6gcoukgqgq\n",
      "Uploaded file 'video106.txt' as: https://generativelanguage.googleapis.com/v1beta/files/6alp5n0t3lvy\n",
      "Uploaded file 'video107.txt' as: https://generativelanguage.googleapis.com/v1beta/files/bsriqqtsx02a\n",
      "Uploaded file 'video108.txt' as: https://generativelanguage.googleapis.com/v1beta/files/887cr7kto0si\n",
      "Uploaded file 'video109.txt' as: https://generativelanguage.googleapis.com/v1beta/files/a1bxki50dsfm\n",
      "Uploaded file 'video110.txt' as: https://generativelanguage.googleapis.com/v1beta/files/o6rl1chfmjf2\n",
      "Uploaded file 'video111.txt' as: https://generativelanguage.googleapis.com/v1beta/files/iyn0cnysfs8b\n",
      "Uploaded file 'video112.txt' as: https://generativelanguage.googleapis.com/v1beta/files/kurj0yc7ykmj\n",
      "Uploaded file 'video113.txt' as: https://generativelanguage.googleapis.com/v1beta/files/fowzn5sexmic\n",
      "Uploaded file 'video114.txt' as: https://generativelanguage.googleapis.com/v1beta/files/v7n6gzkisq8m\n",
      "Uploaded file 'video115.txt' as: https://generativelanguage.googleapis.com/v1beta/files/lspdjlhpv57v\n",
      "Uploaded file 'video116.txt' as: https://generativelanguage.googleapis.com/v1beta/files/t8c9dk2zl2gf\n",
      "Uploaded file 'video117.txt' as: https://generativelanguage.googleapis.com/v1beta/files/ikvc5rlq3eif\n",
      "Uploaded file 'video118.txt' as: https://generativelanguage.googleapis.com/v1beta/files/o2ajhu8zbmhv\n",
      "Waiting for file processing...\n",
      "...all files ready\n",
      "\n",
      "Analyzing innovativeness...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [16:45<00:00,  8.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing proactivity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [13:19<00:00,  6.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing trustworthiness...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [14:17<00:00,  7.33s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "genai.configure(api_key=\"YOUR_API_KEY\")\n",
    "\n",
    "def upload_to_gemini(path, mime_type=None):\n",
    "  \"\"\"Uploads the given file to Gemini.\n",
    "\n",
    "  See https://ai.google.dev/gemini-api/docs/prompting_with_media\n",
    "  \"\"\"\n",
    "  file = genai.upload_file(path, mime_type=mime_type)\n",
    "  print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
    "  return file\n",
    "\n",
    "def wait_for_files_active(files):\n",
    "  \"\"\"Waits for the given files to be active.\n",
    "\n",
    "  Some files uploaded to the Gemini API need to be processed before they can be\n",
    "  used as prompt inputs. The status can be seen by querying the file's \"state\"\n",
    "  field.\n",
    "\n",
    "  This implementation uses a simple blocking polling loop. Production code\n",
    "  should probably employ a more sophisticated approach.\n",
    "  \"\"\"\n",
    "  print(\"Waiting for file processing...\")\n",
    "  for name in (file.name for file in files):\n",
    "    file = genai.get_file(name)\n",
    "    while file.state.name == \"PROCESSING\":\n",
    "      print(\".\", end=\"\", flush=True)\n",
    "      time.sleep(10)\n",
    "      file = genai.get_file(name)\n",
    "    if file.state.name != \"ACTIVE\":\n",
    "      raise Exception(f\"File {file.name} failed to process\")\n",
    "  print(\"...all files ready\")\n",
    "  print()\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-pro\",\n",
    "  generation_config=generation_config,\n",
    ")\n",
    "\n",
    "# TODO Make these files available on the local file system\n",
    "# You may need to update the file paths\n",
    "if os.path.exists('gemini_text/files.pkl'):\n",
    "    with open('gemini_text/files.pkl', 'rb') as file:\n",
    "        files = pickle.load(file)\n",
    "else:\n",
    "  files = []\n",
    "  for i in range(1, 119):\n",
    "      try:\n",
    "        files.append(upload_to_gemini(f\"transcript/Script_txt/video{str(i)}.txt\", mime_type=\"text/txt\"))\n",
    "      except:\n",
    "        print(f\"video{str(i)}.txt is not found\")\n",
    "        continue\n",
    "\n",
    "  # Some files have a processing delay. Wait for them to be ready.\n",
    "  wait_for_files_active(files)\n",
    "  with open('gemini_text/files.pkl', 'wb') as file_save:\n",
    "      pickle.dump(files, file_save)\n",
    "\n",
    "# add assetiveness if want more\n",
    "# drop future orientation if want less\n",
    "variables = ['innovativeness','proactivity','trustworthiness']\n",
    "df = pd.DataFrame()\n",
    "for var in variables:\n",
    "  print(f\"Analyzing {var}...\")\n",
    "  if os.path.exists(f\"gemini_text/{var}.pkl\"):\n",
    "    with open(f\"gemini_text/{var}.pkl\", \"rb\") as file:\n",
    "        result = pickle.load(file)\n",
    "  else:\n",
    "    result = {'video':[],var:[]}\n",
    "  if len(result['video']) == len(files):\n",
    "    continue\n",
    "  for file in tqdm(files):\n",
    "    if file.display_name in result['video']:\n",
    "        continue\n",
    "    chat_session = model.start_chat()\n",
    "    response = chat_session.send_message([f\"Analyze the {var.replace('-',' ')} of small business owners in entrepreneurship from the text file. Provide a rating on a scale of 1 to 10.\",file], request_options={\"timeout\": 1000})\n",
    "    result['video'].append(file.display_name)\n",
    "    result[var].append(str(response.parts[0]))\n",
    "    with open(f\"gemini_text/{var}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(result, file)\n",
    "    \n",
    "  df_temp = pd.DataFrame(result)\n",
    "  df = df.merge(df_temp, on='video', how='outer') if not df.empty else df_temp\n",
    "  df.to_csv('gemini_text/overall_score.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/zhouzhuofu/Desktop/RA/moduality'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def save_material():\n",
    "\n",
    "    while True:\n",
    "        # Prompt for the video number\n",
    "        video_number = input(\"Enter the video number: \")\n",
    "        \n",
    "        # Validate video number\n",
    "        if not video_number.isdigit():\n",
    "            print(\"Finished saving materials.\")\n",
    "            return\n",
    "        \n",
    "        if int(video_number) <= 0:\n",
    "            print(\"Finished saving materials.\")\n",
    "            return\n",
    "        # Generate the file name\n",
    "        file_name = f\"sentiment/video{video_number}.txt\"\n",
    "        \n",
    "        # Prompt for the material\n",
    "        print(f\"Paste the material below for video{video_number}. Press Enter twice to save:\")\n",
    "        lines = []\n",
    "        line = input()\n",
    "        if line == \"\":\n",
    "            break\n",
    "        lines.append(line)\n",
    "        \n",
    "        # Join the lines into a single string\n",
    "        material = \"\\n\".join(lines)\n",
    "        \n",
    "        # Save the material to the corresponding file\n",
    "        with open(file_name, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(material)\n",
    "        \n",
    "        print(f\"Material saved to {file_name}\")\n",
    "\n",
    "# Run the function\n",
    "save_material()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict ={'video':[], 'script':[], 'sentiment':[]}\n",
    "for i in range(1, 118):\n",
    "    if i == 37:\n",
    "        continue\n",
    "    script_path = f'Script_txt/video{str(i)}.txt'\n",
    "    sentiment_path = f'sentiment/video{str(i)}.txt'\n",
    "    with open(script_path, 'r', encoding='utf-8') as f:\n",
    "        result_dict['script'].append(f.read())\n",
    "    with open(sentiment_path, 'r',encoding='utf-8') as f:\n",
    "        result_dict['sentiment'].append(f.read())\n",
    "    result_dict['video'].append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>script</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>video1.mp4\\n\\nSpeaker1: [00:00:01] Hamoodur Ra...</td>\n",
       "      <td>**Segment 1: [00:00:01] Hamoodur Rahman. Moham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>video2.mp4\\n\\nSpeaker1: [00:00:01] Mommy, is i...</td>\n",
       "      <td>1. **Segment: [00:00:01] to [00:00:12]**    - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>video3.mp4\\n\\nSpeaker1: [00:00:00] Hi, I'm Rob...</td>\n",
       "      <td>**Segment 1**  - **Timestamp:** [00:00:00]  - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>video4.mp4\\n\\nSpeaker1: [00:00:01] Hamoodur Ra...</td>\n",
       "      <td>### Segment 1: [00:00:01] - **Sentiment:** Neu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>video5.mp4\\n\\nSpeaker1: [00:00:08] I am a prof...</td>\n",
       "      <td>**Segment: [00:00:08] - [00:01:47]**  1. **Sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video                                             script  \\\n",
       "0      1  video1.mp4\\n\\nSpeaker1: [00:00:01] Hamoodur Ra...   \n",
       "1      2  video2.mp4\\n\\nSpeaker1: [00:00:01] Mommy, is i...   \n",
       "2      3  video3.mp4\\n\\nSpeaker1: [00:00:00] Hi, I'm Rob...   \n",
       "3      4  video4.mp4\\n\\nSpeaker1: [00:00:01] Hamoodur Ra...   \n",
       "4      5  video5.mp4\\n\\nSpeaker1: [00:00:08] I am a prof...   \n",
       "\n",
       "                                           sentiment  \n",
       "0  **Segment 1: [00:00:01] Hamoodur Rahman. Moham...  \n",
       "1  1. **Segment: [00:00:01] to [00:00:12]**    - ...  \n",
       "2  **Segment 1**  - **Timestamp:** [00:00:00]  - ...  \n",
       "3  ### Segment 1: [00:00:01] - **Sentiment:** Neu...  \n",
       "4  **Segment: [00:00:08] - [00:01:47]**  1. **Sen...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(result_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('startup_audio_sentiment_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "variables = ['assertiveness','creativity','enthusiasm','future-orientation','goal-orientation','optimism','proactive-personality','']\n",
    "df = pd.DataFrame()\n",
    "for var in variables:\n",
    "    with open(f\"{var}/result.txt\", \"r\") as file:\n",
    "        raw_output = file.read().lower().replace('\\n','')\n",
    "    text_cleaned = re.sub(r\"video\\s+(\\d+)\", r\"video\\1\", raw_output)\n",
    "    pattern = r\"(video[0-9]+).*?([0-9]+(\\.\\d+)?/10)\"\n",
    "    matches = re.findall(pattern, text_cleaned)\n",
    "    rating_dict = {'video':[], var:[]}\n",
    "# Print results\n",
    "    for match in matches:\n",
    "        video, rating = int(match[0].replace('video','')), float(match[1].replace('/10',''))  # Extract video name and full rating\n",
    "        #print(f\"{video}: {rating}\")  # Print video name and rating \n",
    "        rating_dict['video'].append(video)\n",
    "        rating_dict[var].append(rating)\n",
    "    df_temp = pd.DataFrame(rating_dict).drop_duplicates(subset='video')\n",
    "    df = df.merge(df_temp, on='video', how='outer') if not df.empty else df_temp\n",
    "    #print(rating_dict)\n",
    "    #break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('startup_audio_var.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame.from_dict(rating_dict).drop_duplicates(subset='video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>assertiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>112</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>113</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>115</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>117</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>118</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     video  assertiveness\n",
       "0        1            6.0\n",
       "1        2            7.0\n",
       "2        3            8.0\n",
       "3        4            6.0\n",
       "5        5            5.0\n",
       "..     ...            ...\n",
       "111    112            7.0\n",
       "112    113            7.0\n",
       "114    115            6.0\n",
       "115    117            7.0\n",
       "116    118            6.0\n",
       "\n",
       "[112 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video1: 6/10\n",
      "video2: 7/10\n",
      "video3: 8/10\n",
      "video4: 6/10\n",
      "video1: 6/10\n",
      "video5: 5/10\n",
      "video6: 9/10\n",
      "video7: 9/10\n",
      "video6: 9/10\n",
      "video8: 8/10\n",
      "video9: 7/10\n",
      "video10: 7/10\n",
      "video11: 9/10\n",
      "video12: 7/10\n",
      "video13: 8/10\n",
      "video14: 6/10\n",
      "video15: 7/10\n",
      "video16: 9/10\n",
      "video17: 8/10\n",
      "video18: 8/10\n",
      "video19: 7/10\n",
      "video20: 8/10\n",
      "video21: 8/10\n",
      "video22: 7/10\n",
      "video23: 7/10\n",
      "video24: 8/10\n",
      "video25: 7/10\n",
      "video26: 7/10\n",
      "video27: 9/10\n",
      "video28: 7/10\n",
      "video29: 6/10\n",
      "video30: 5/10\n",
      "video31: 7/10\n",
      "video32: 7/10\n",
      "video33: 8/10\n",
      "video34: 8/10\n",
      "video35: 6/10\n",
      "video36: 7/10\n",
      "video38: 7/10\n",
      "video39: 8/10\n",
      "video40: 7/10\n",
      "video41: 8/10\n",
      "video42: 9/10\n",
      "video43: 7/10\n",
      "video44: 8/10\n",
      "video45: 7/10\n",
      "video46: 8/10\n",
      "video47: 7/10\n",
      "video48: 7/10\n",
      "video49: 8/10\n",
      "video50: 8/10\n",
      "video51: 8/10\n",
      "video52: 6/10\n",
      "video51: 7/10\n",
      "video55: 7/10\n",
      "video56: 6/10\n",
      "video57: 7/10\n",
      "video58: 6/10\n",
      "video59: 5/10\n",
      "video60: 6/10\n",
      "video61: 7/10\n",
      "video62: 6/10\n",
      "video63: 7/10\n",
      "video64: 5/10\n",
      "video65: 7/10\n",
      "video66: 8/10\n",
      "video67: 7/10\n",
      "video68: 8/10\n",
      "video69: 5/10\n",
      "video70: 6/10\n",
      "video71: 6/10\n",
      "video72: 6/10\n",
      "video73: 6/10\n",
      "video74: 7/10\n",
      "video75: 4/10\n",
      "video76: 7/10\n",
      "video77: 6/10\n",
      "video78: 7/10\n",
      "video79: 6/10\n",
      "video80: 7/10\n",
      "video81: 6/10\n",
      "video82: 7/10\n",
      "video83: 7/10\n",
      "video84: 5/10\n",
      "video85: 6/10\n",
      "video86: 6/10\n",
      "video87: 6/10\n",
      "video86: 6/10\n",
      "video89: 7/10\n",
      "video90: 7/10\n",
      "video91: 6/10\n",
      "video92: 6/10\n",
      "video93: 7/10\n",
      "video94: 4/10\n",
      "video95: 6/10\n",
      "video96: 6/10\n",
      "video97: 3/10\n",
      "video98: 6/10\n",
      "video99: 6/10\n",
      "video100: 7/10\n",
      "video101: 7/10\n",
      "video102: 5/10\n",
      "video103: 7/10\n",
      "video104: 8/10\n",
      "video105: 6/10\n",
      "video106: 6/10\n",
      "video107: 7/10\n",
      "video108: 6/10\n",
      "video109: 6/10\n",
      "video110: 6/10\n",
      "video111: 5/10\n",
      "video112: 7/10\n",
      "video113: 7/10\n",
      "video112: 6/10\n",
      "video115: 6/10\n",
      "video117: 7/10\n",
      "video118: 6/10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pattern = r\"(video[0-9]+).*?([0-9]+(\\.\\d+)?/10)\"\n",
    "matches = re.findall(pattern, text_cleaned)\n",
    "\n",
    "# Print results\n",
    "for match in matches:\n",
    "    video, rating = match[0], match[1]  # Extract video name and full rating\n",
    "    print(f\"{video}: {rating}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.2.1\n",
      "Uninstalling numpy-2.2.1:\n",
      "  Would remove:\n",
      "    /opt/anaconda3/envs/Big_data/bin/f2py\n",
      "    /opt/anaconda3/envs/Big_data/bin/numpy-config\n",
      "    /opt/anaconda3/envs/Big_data/lib/python3.13/site-packages/numpy-2.2.1.dist-info/*\n",
      "    /opt/anaconda3/envs/Big_data/lib/python3.13/site-packages/numpy/*\n",
      "Proceed (Y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: numpy in /opt/anaconda3/envs/Big_data/lib/python3.13/site-packages (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall numpy\n",
    "!pip install numpy\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing future-orientation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [44:35<00:00, 22.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing self-confidence...\n",
      "Analyzing creativity...\n",
      "Analyzing enthusiasm...\n",
      "Analyzing optimism...\n",
      "Analyzing proactive-personality...\n",
      "Analyzing trustworthiness...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 81/117 [00:16<00:07,  4.95it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 91\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     90\u001b[0m chat_session \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mstart_chat()\n\u001b[0;32m---> 91\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchat_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAnalyze the \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m of small business owners in entrepreneurship from the videos using the visual information. Provide a rating on a scale of 1 to 10.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimeout\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(file\u001b[38;5;241m.\u001b[39mdisplay_name)\n\u001b[1;32m     93\u001b[0m result[var]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(response\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ensemble_env/lib/python3.12/site-packages/google/generativeai/generative_models.py:578\u001b[0m, in \u001b[0;36mChatSession.send_message\u001b[0;34m(self, content, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_count\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid configuration: The chat functionality does not support `candidate_count` greater than 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n\u001b[0;32m--> 578\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools_lib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_response(response\u001b[38;5;241m=\u001b[39mresponse, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_automatic_function_calling \u001b[38;5;129;01mand\u001b[39;00m tools_lib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ensemble_env/lib/python3.12/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ensemble_env/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ensemble_env/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ensemble_env/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ensemble_env/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ensemble_env/lib/python3.12/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ensemble_env/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ensemble_env/lib/python3.12/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ensemble_env/lib/python3.12/site-packages/grpc/_interceptor.py:329\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m--> 329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interceptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mresult(), call\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ensemble_env/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:79\u001b[0m, in \u001b[0;36m_LoggingClientInterceptor.intercept_unary_unary\u001b[0;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[1;32m     64\u001b[0m     grpc_request \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayload\u001b[39m\u001b[38;5;124m\"\u001b[39m: request_payload,\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequestMethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrpc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[1;32m     68\u001b[0m     }\n\u001b[1;32m     69\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     71\u001b[0m         extra\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m         },\n\u001b[1;32m     77\u001b[0m     )\n\u001b[0;32m---> 79\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     response_metadata \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtrailing_metadata()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ensemble_env/lib/python3.12/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    306\u001b[0m (\n\u001b[1;32m    307\u001b[0m     new_method,\n\u001b[1;32m    308\u001b[0m     new_timeout,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m     new_compression,\n\u001b[1;32m    313\u001b[0m ) \u001b[38;5;241m=\u001b[39m _unwrap_client_call_details(new_details, client_call_details)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ensemble_env/lib/python3.12/site-packages/grpc/_channel.py:1195\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwith_call\u001b[39m(\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1185\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1191\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, grpc\u001b[38;5;241m.\u001b[39mCall]:\n\u001b[1;32m   1192\u001b[0m     (\n\u001b[1;32m   1193\u001b[0m         state,\n\u001b[1;32m   1194\u001b[0m         call,\n\u001b[0;32m-> 1195\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ensemble_env/lib/python3.12/site-packages/grpc/_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[0;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "genai.configure(api_key=\"YOUR_API_KEY\")\n",
    "\n",
    "def upload_to_gemini(path, mime_type=None):\n",
    "  \"\"\"Uploads the given file to Gemini.\n",
    "\n",
    "  See https://ai.google.dev/gemini-api/docs/prompting_with_media\n",
    "  \"\"\"\n",
    "  file = genai.upload_file(path, mime_type=mime_type)\n",
    "  print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
    "  return file\n",
    "\n",
    "def wait_for_files_active(files):\n",
    "  \"\"\"Waits for the given files to be active.\n",
    "\n",
    "  Some files uploaded to the Gemini API need to be processed before they can be\n",
    "  used as prompt inputs. The status can be seen by querying the file's \"state\"\n",
    "  field.\n",
    "\n",
    "  This implementation uses a simple blocking polling loop. Production code\n",
    "  should probably employ a more sophisticated approach.\n",
    "  \"\"\"\n",
    "  print(\"Waiting for file processing...\")\n",
    "  for name in (file.name for file in files):\n",
    "    file = genai.get_file(name)\n",
    "    while file.state.name == \"PROCESSING\":\n",
    "      print(\".\", end=\"\", flush=True)\n",
    "      time.sleep(10)\n",
    "      file = genai.get_file(name)\n",
    "    if file.state.name != \"ACTIVE\":\n",
    "      raise Exception(f\"File {file.name} failed to process\")\n",
    "  print(\"...all files ready\")\n",
    "  print()\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-pro\",\n",
    "  generation_config=generation_config,\n",
    ")\n",
    "\n",
    "# TODO Make these files available on the local file system\n",
    "# You may need to update the file paths\n",
    "if os.path.exists('gemini_video/files.pkl'):\n",
    "    with open('gemini_video/files.pkl', 'rb') as file:\n",
    "        files = pickle.load(file)\n",
    "else:\n",
    "  files = []\n",
    "  for i in range(1, 119):\n",
    "      try:\n",
    "        files.append(upload_to_gemini(f\"dataset/startup_videos/video{str(i)}.mp4\", mime_type=\"video/mp4\"))\n",
    "      except:\n",
    "        print(f\"video{str(i)}.mp4 is not found\")\n",
    "        continue\n",
    "\n",
    "  # Some files have a processing delay. Wait for them to be ready.\n",
    "  wait_for_files_active(files)\n",
    "  with open('gemini_video/files.pkl', 'wb') as file_save:\n",
    "      pickle.dump(files, file_save)\n",
    "\n",
    "# add assetiveness if want more\n",
    "# drop future orientation if want less\n",
    "variables = ['future-orientation','self-confidence','creativity','enthusiasm','optimism','proactive-personality','trustworthiness']\n",
    "df = pd.DataFrame()\n",
    "for var in variables:\n",
    "  print(f\"Analyzing {var}...\")\n",
    "  if os.path.exists(f\"gemini_video/{var}.pkl\"):\n",
    "    with open(f\"gemini_video/{var}.pkl\", \"rb\") as file:\n",
    "        result = pickle.load(file)\n",
    "  else:\n",
    "    result = {'video':[],var:[]}\n",
    "  if len(result['video']) == len(files):\n",
    "    continue\n",
    "  for file in tqdm(files):\n",
    "    if file.display_name in result['video']:\n",
    "        continue\n",
    "    chat_session = model.start_chat()\n",
    "    response = chat_session.send_message([f\"Analyze the {var.replace('-',' ')} of small business owners in entrepreneurship from the videos using the visual information. Provide a rating on a scale of 1 to 10.\",file], request_options={\"timeout\": 1000})\n",
    "    result['video'].append(file.display_name)\n",
    "    result[var].append(str(response.parts[0]))\n",
    "    with open(f\"gemini_video/{var}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(result, file)\n",
    "    \n",
    "  df_temp = pd.DataFrame(result)\n",
    "  df = df.merge(df_temp, on='video', how='outer') if not df.empty else df_temp\n",
    "  df.to_csv('gemini_video/overall_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing trustworthiness...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 82/117 [16:40<07:06, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 504 Deadline Exceeded for video83.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [39:35<00:00, 20.30s/it]\n"
     ]
    }
   ],
   "source": [
    "variables = ['self-confidence','creativity','enthusiasm','optimism','proactive-personality','trustworthiness']\n",
    "variables = ['trustworthiness']\n",
    "df = pd.read_csv('gemini/overall_score.csv', index_col=0)\n",
    "for var in variables:\n",
    "  print(f\"Analyzing {var}...\")\n",
    "  if os.path.exists(f\"gemini/{var}.pkl\"):\n",
    "    with open(f\"gemini/{var}.pkl\", \"rb\") as file:\n",
    "        result = pickle.load(file)\n",
    "  else:\n",
    "    result = {'video':[],var:[]}\n",
    "  for file in tqdm(files):\n",
    "    if file.display_name in result['video']:\n",
    "        continue\n",
    "    chat_session = model.start_chat()\n",
    "    try:\n",
    "      response = chat_session.send_message([f\"Analyze the {var.replace('-',' ')} of small business owners in entrepreneurship from the vidoes using the visual information. Provide a rating on a scale of 1 to 10.\",file], request_options={\"timeout\": 1000})\n",
    "      result['video'].append(file.display_name)\n",
    "      result[var].append(str(response.parts[0]))\n",
    "    except Exception as e:\n",
    "      print(f\"Error: {e} for {file.display_name}\")\n",
    "    with open(f\"gemini/{var}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(result, file)\n",
    "    \n",
    "  df_temp = pd.DataFrame(result)\n",
    "  df = df.merge(df_temp, on='video', how='outer') if not df.empty else df_temp\n",
    "  df.to_csv('gemini/overall_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>future-orientation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>114</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>115</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>116</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>117</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>118</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     video future-orientation\n",
       "0        1               10.0\n",
       "1        2                9.5\n",
       "2        3                9.0\n",
       "3        4                 10\n",
       "4        5                  9\n",
       "..     ...                ...\n",
       "112    114                9.5\n",
       "113    115                9.5\n",
       "114    116                9.5\n",
       "115    117                9.0\n",
       "116    118                8.5\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the index and rating\n",
    "import re\n",
    "\n",
    "def clean_index(index_string):\n",
    "    return int(index_string.replace('video','').replace('.mp4',''))\n",
    "\n",
    "def retrieve_rating(rating_string):\n",
    "    if isinstance(rating_string, str):\n",
    "        cleaned_text = re.sub(r'\\\\[0-9]{3}', '', rating_string)\n",
    "        cleaned_text = re.sub(r'\\\\n', '', cleaned_text)  \n",
    "        cleaned_text = re.sub(r'/10', '', cleaned_text)\n",
    "        cleaned_text = cleaned_text.replace('out of 10','')\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "        numbers = re.findall(r'\\b(?:10(?:\\.0+)?|[1-9](?:\\.\\d+)?)\\b', cleaned_text)\n",
    "        if not numbers:\n",
    "            return None\n",
    "        elif len(numbers) == 1:\n",
    "            return float(numbers[0])\n",
    "        else:\n",
    "            return numbers[-1]\n",
    "    else:\n",
    "        return rating_string\n",
    "df = pd.read_csv('gemini_video/overall_score.csv', index_col=0)\n",
    "df['video'] = df['video'].apply(clean_index)\n",
    "for var in df.columns[1:]:\n",
    "    \n",
    "    df[var] = df[var].apply(retrieve_rating)\n",
    "df.sort_values('video', inplace=True)\n",
    "df.to_csv('gemini_video/overall_score_cleaned.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemble_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
